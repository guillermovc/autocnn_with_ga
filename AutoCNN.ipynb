{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuCigbl9I9Tf"
   },
   "source": [
    "# Generating CNN architectures automatically with genetic algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7H7nvr-Jhfm",
    "outputId": "e31c8737-493e-4b49-fac9-d78e95be9b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "import tensorflow as tf\n",
    "from tf.keras.layers import Input, Add, Dense, Activation, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tf.keras.models import Model, load_model\n",
    "from tf.keras.utils import to_categorical\n",
    "from tf.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 8)\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_result(history):\n",
    "    # plotting the training accuracy and loss\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'],loc='upper left')\n",
    "    plt.figure(figsize = (60,20))\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'],)\n",
    "    plt.plot(history.history['val_loss'],)\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'], loc = 'upper left')\n",
    "    plt.figure(figsize = (20,10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOxcyxXQzcPw"
   },
   "source": [
    "# ResNets\n",
    "\n",
    "This project is based in ResNets, using this kind of Convolutional Neural Networks allows us to make very deep neural networks avoiding gradient vanishing and overfitting issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "L9zdfg8s4UH3"
   },
   "outputs": [],
   "source": [
    "# Static class Layer\n",
    "class Layer():\n",
    "    @staticmethod\n",
    "    def skip_layer_encode() -> str :\n",
    "        \"\"\"\n",
    "        Return a randomly initialized skip layer with two convolutions\n",
    "\n",
    "        Returns:\n",
    "            str: String representing the number of filters in the two\n",
    "                 convolutions\n",
    "        \"\"\"\n",
    "        f1 = 2 ** random.randint(5, 9) # number from 32 to 512\n",
    "        f2 = 2 ** random.randint(5, 9) # number from 32 to 512\n",
    "        return f\"{f1}_{f2}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def pooling_layer_encode() -> str:\n",
    "        \"\"\"\n",
    "        Returns a pooling layer\n",
    "\n",
    "        Returns:\n",
    "            str: Mean or Max pooling layer representation\n",
    "        \"\"\"\n",
    "        q = random.random()\n",
    "        if q < 0.5:\n",
    "            return \"max\"\n",
    "        else:\n",
    "            return \"mean\"\n",
    "        \n",
    "    @staticmethod\n",
    "    def random_layer(skip_layer_prob=0.70) -> str:\n",
    "        \"\"\"\n",
    "        Returns randombly skip or pooling layer\n",
    "\n",
    "        Args:\n",
    "            skip_layer_prob (float, optional): Probability of getting skip layer. \n",
    "            Defaults to 0.75.\n",
    "\n",
    "        Returns:\n",
    "            str: A string representation of a layer\n",
    "        \"\"\"\n",
    "        r = random.random()\n",
    "\n",
    "        if r < skip_layer_prob:\n",
    "            return Layer.skip_layer_encode()\n",
    "        else:\n",
    "            return Layer.pooling_layer_encode()\n",
    "        \n",
    "    @staticmethod\n",
    "    def skip_layer(X, f1, f2, kernel = (3,3), stride = (1,1)) -> tf.keras.layers:\n",
    "        \"\"\"\n",
    "        Returns a convolutional block of a ResNet\n",
    "\n",
    "        Args:\n",
    "            X (keras.Layers): Previous layer of a CNN\n",
    "            f1 (int): Number of filters in first convolution\n",
    "            f2 (int): Number of filters in second convolution\n",
    "            kernel (tuple, optional): Filter shape. Defaults to (3,3).\n",
    "            stride (tuple, optional): Stride shape. Defaults to (1,1).\n",
    "\n",
    "        Returns:\n",
    "            keras.layers: The output of a convolutional block\n",
    "        \"\"\"\n",
    "        inputs = X\n",
    "\n",
    "        # First convolution\n",
    "        layer = Conv2D(f1, kernel_size=kernel, strides=stride, padding=\"same\")(X)\n",
    "        layer = BatchNormalization(axis=3)(layer)\n",
    "        layer = Activation(\"relu\")(layer)\n",
    "\n",
    "        # Second convolution\n",
    "        layer = Conv2D(f2, kernel_size=kernel, strides=stride, padding=\"same\")(layer)\n",
    "        layer = BatchNormalization(axis=3)(layer)\n",
    "\n",
    "        # Inter convolution (makes sure that the dimensionality at the skip layers are the same)\n",
    "        inputs = Conv2D(f2, kernel_size=(1,1), strides=stride, padding=\"same\")(inputs)\n",
    "\n",
    "        # We add the input and the second convolution layers\n",
    "        outputs = Add()([inputs, layer])\n",
    "        outputs = Activation(\"relu\")(outputs)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def pooling_layer(X, pooling_type, kernel = (2,2), stride = (2,2)) -> keras.layers:\n",
    "        \"\"\"\n",
    "        Returns whether a MeanPooling2D or MaxPooling2D layer\n",
    "\n",
    "        Args:\n",
    "            X (keras.layers): Previous layer of a CNN\n",
    "            pooling_type (str): The type of pooling layer\n",
    "            kernel (tuple, optional): Pooling filter shape. Defaults to (2,2).\n",
    "            stride (tuple, optional): Stride shape. Defaults to (2,2).\n",
    "\n",
    "        Returns:\n",
    "            tf.keras.layers: Whether a Max or Mean pooling layer\n",
    "        \"\"\"\n",
    "        pooling_choices = {\n",
    "            \"max\": MaxPooling2D,\n",
    "            \"mean\": AveragePooling2D\n",
    "        }\n",
    "\n",
    "        return pooling_choices[pooling_type](pool_size=kernel, strides=stride, padding=\"same\")(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_BU9tZpqJnM"
   },
   "source": [
    "# Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXIEZ5hTqLm-"
   },
   "source": [
    "## The CNN class (individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "K2yD0lBe5Emr"
   },
   "outputs": [],
   "source": [
    "# This class represents each individual of our population\n",
    "class CNN:\n",
    "\n",
    "    def __init__(self, encoding:str, input_shape:tuple, output_shape:int) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Class constructor\n",
    "\n",
    "        Args:\n",
    "            encoding (str): Encoding representation of the CNN\n",
    "            input_shape (tuple): Input shape of the CNN (height, width, channels)\n",
    "            output_shape (int): Number of classes of the CNN\n",
    "        \"\"\"\n",
    "\n",
    "        # Genetic Algorithm stuff\n",
    "        self.genes = encoding.split(\"-\") # List of genes (cnn layers)\n",
    "        self.num_genes = len(self.genes) # Number of genes (cnn layers)\n",
    "\n",
    "        # CNN stuff\n",
    "        self.encoding = encoding         # Encoded representation of the CNN\n",
    "        self.input_shape = input_shape   # Input shape (WIDTH, HEIGHT, CHANNELS)\n",
    "        self.output_shape = output_shape # Output shape (number of classes)\n",
    "        self.accuracy = 0.0              # Accuracy of the model\n",
    "        self.process_time = 0.0          # Time of the model to make an inference\n",
    "        self.training_time = 0.0         # Time taken to train\n",
    "\n",
    "    def generate_model(self) -> tf.keras.Model:\n",
    "        \"\"\"\n",
    "        Generates a Keras model from the encoding\n",
    "\n",
    "        Returns:\n",
    "            model: tensorflow.keras.Model\n",
    "        \"\"\"\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        outputs = inputs\n",
    "\n",
    "        # Create a list of layers from the encoding of the cnn\n",
    "        layers = []\n",
    "        for layer in self.encoding.split(\"-\"):\n",
    "            if layer == \"mean\":\n",
    "                outputs = Layer.pooling_layer(outputs, \"mean\")\n",
    "            elif layer == \"max\":\n",
    "                outputs=  Layer.pooling_layer(outputs, \"max\")\n",
    "            else:\n",
    "                # Skip layer\n",
    "                f1, f2 = layer.split(\"_\")\n",
    "                outputs = Layer.skip_layer(outputs, int(f1), int(f2))\n",
    "\n",
    "        # Fully connected layers\n",
    "        outputs = GlobalMaxPooling2D()(outputs)\n",
    "#         outputs = Dense(32, activation=\"relu\")(outputs)\n",
    "        outputs = Dense(self.output_shape, activation=\"softmax\")(outputs)\n",
    "\n",
    "        return Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "\n",
    "        \"\"\"\n",
    "        String representation of the object.\n",
    "        \"\"\"\n",
    "\n",
    "        return f\"\"\"Model encoding: {self.encoding}, \\nModel Accuracy: {self.accuracy},\\nModel process time: {self.process_time}\"\"\"\n",
    "\n",
    "    def get_info(self) -> dict:\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns a dict with the information of the current individual.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing class important attributes.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"depth\": self.num_genes,\n",
    "            \"accuracy\" : self.accuracy,\n",
    "            \"process time\": self.process_time,\n",
    "            \"training time\": self.training_time,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7ZatuHUqQdn"
   },
   "source": [
    "## The Population class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "qMSQ3sYLt5pY"
   },
   "outputs": [],
   "source": [
    "class Population:\n",
    "\n",
    "    def __init__(self, n_individuals, min_genes, max_genes) -> None:\n",
    "        \"\"\"\n",
    "        Class constructor\n",
    "\n",
    "        Args:\n",
    "            n_individuals (int): Number of individuals\n",
    "            min_genes (int): Minimum number of genes an individual can have\n",
    "            max_genes (int): Maximum number of genes an individual can have\n",
    "        \"\"\"\n",
    "        self.n_individuals = n_individuals\n",
    "        self.min_genes = min_genes\n",
    "        self.max_genes = max_genes\n",
    "        self.individuals = None\n",
    "        self.best_individual = None\n",
    "        self.mean_accuracy = 0.0\n",
    "\n",
    "    def initialize(self, input_shape, output_shape) -> None:\n",
    "        \"\"\"\n",
    "        Randomly initialize the population\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Shape of the input\n",
    "            output_shape (int): Number of classes\n",
    "        \"\"\"\n",
    "        population = [] # List of CNN objects\n",
    "        \n",
    "        for _ in range(self.n_individuals):\n",
    "            new_individual = self.generate_individual(input_shape, output_shape)\n",
    "            population.append(new_individual)\n",
    "\n",
    "        self.individuals = population\n",
    "\n",
    "    def generate_individual(self, input_shape, output_shape) -> CNN:\n",
    "        \"\"\"Randombly generates and individual\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Shape of the input (width, height, n_channels)\n",
    "            output_shape (int): Number of output classes\n",
    "\n",
    "        Returns:\n",
    "            CNN: Randomly initialized instance of the CNN class\n",
    "        \"\"\"\n",
    "        depth = random.randint(self.min_genes, self.max_genes)\n",
    "        layers = [Layer.random_layer() for _ in range(depth)]\n",
    "        layers = \"-\".join(layers)\n",
    "\n",
    "        return CNN(layers, input_shape, output_shape)\n",
    "\n",
    "    def compute_mean_accuracy(self) -> None:\n",
    "        \"\"\"\n",
    "        Computes the mean accuracy of the population\n",
    "        \"\"\"\n",
    "        sum_accuracy = sum(individual.accuracy for individual in self.individuals)\n",
    "        self.mean_accuracy = sum_accuracy / len(self.individuals)\n",
    "\n",
    "    def print(self) -> None:\n",
    "        \"\"\"\n",
    "        Print a table summarizing the information of the population\n",
    "        \"\"\"\n",
    "        individuals_info = []\n",
    "        for individual in self.individuals:\n",
    "            individuals_info.append(\n",
    "                [individual.num_genes, \"_\".join(individual.genes[:10]), round(individual.accuracy, 2),\n",
    "                 round(individual.process_time, 2)]\n",
    "            )\n",
    "\n",
    "        print(tabulate(individuals_info,\n",
    "        headers=[\"CNN Depth\", \"Encoding (just first layers)\", \"Accuracy\", \"Process time\"],\n",
    "        numalign=\"center\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CnH-TrUqSg_"
   },
   "source": [
    "## The GeneticAlgorithm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "lyiZk9R-5VfC"
   },
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "\n",
    "    def __init__(self, population_size, min_genes, max_genes, fitness_func, mutation_rate, \n",
    "                crossover_rate, num_generations, saved_cnns, training_params) -> None:\n",
    "        self.population_size = population_size\n",
    "        self.min_genes = min_genes\n",
    "        self.max_genes = max_genes\n",
    "        self.fitness_func = fitness_func\n",
    "        self.num_generations = num_generations\n",
    "        \n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "\n",
    "        self.population = Population(population_size, min_genes, max_genes)\n",
    "        self.input_shape = training_params[\"X_train\"][0].shape\n",
    "        self.output_shape = training_params[\"y_train_cat\"][0].shape[0]\n",
    "        \n",
    "        self.saved_cnns = saved_cnns\n",
    "        self.training_params = training_params\n",
    "\n",
    "        self.accuracy_history = []\n",
    "\n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def save_architectures(self) -> None:\n",
    "        \"\"\"\n",
    "        Save the evaluated architectures of the population in a JSON file\n",
    "        \"\"\"\n",
    "        # Directly from dictionary\n",
    "        with open('evaluated_architectures.json', 'w') as outfile:\n",
    "            json.dump(self.saved_cnns, outfile, indent=4)\n",
    "\n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def evaluate_population(self) -> None:\n",
    "        \"\"\"\n",
    "        Evaluate every CNN in the population and calculates its metrics\n",
    "        \"\"\"\n",
    "\n",
    "        # Get training params\n",
    "        X_train = self.training_params[\"X_train\"]\n",
    "        X_test = self.training_params[\"X_test\"]\n",
    "        y_train_cat = self.training_params[\"y_train_cat\"]\n",
    "        y_test_cat = self.training_params[\"y_test_cat\"]\n",
    "        epochs = self.training_params[\"epochs\"]\n",
    "        batch_size = self.training_params[\"batch_size\"]\n",
    "\n",
    "        if self.population.best_individual is not None:\n",
    "            best_acc = self.population.best_individual.accuracy\n",
    "        else:\n",
    "            best_acc = 0.0\n",
    "\n",
    "        for individual in self.population.individuals:\n",
    "            print(\"\".center(100, \"=\"))\n",
    "            # Check if our architecture is already in the saved cnns dict\n",
    "            if individual.encoding in self.saved_cnns:\n",
    "                print(f\"Architecture {individual.encoding} already evaluated\")\n",
    "            else:\n",
    "                # Creating individual model\n",
    "                model = individual.generate_model()\n",
    "                model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "                print(f\"Architecture: {individual.encoding}, Depth: {individual.num_genes}\")\n",
    "                print(\"Training ...\")\n",
    "                \n",
    "                # Training the model\n",
    "                time1 = time.perf_counter()\n",
    "                history = model.fit(X_train, y_train_cat, epochs = epochs, batch_size = batch_size, \n",
    "                                               validation_split=0.15, verbose=0)\n",
    "                time2 = time.perf_counter()\n",
    "                individual.training_time = (time2 - time1)/60\n",
    "\n",
    "                # Evaluating the model\n",
    "                print(\"Evaluating the model with unseen data ...\")\n",
    "                val_loss, val_acc = model.evaluate(X_test, y_test_cat, batch_size=batch_size)\n",
    "\n",
    "                # Measuring time\n",
    "                time1 = time.perf_counter()\n",
    "                predictions = model.predict(X_test)\n",
    "                time2 = time.perf_counter()\n",
    "                individual.process_time = ((time2 - time1)/X_test.shape[0]) * 1000\n",
    "                print(f\"Process time: {individual.process_time} milliseconds.\")\n",
    "                \n",
    "                individual.accuracy = val_acc\n",
    "\n",
    "                if val_acc > best_acc:\n",
    "                    self.population.best_individual = individual\n",
    "                    best_acc = val_acc\n",
    "\n",
    "                self.saved_cnns[individual.encoding] = individual.get_info()\n",
    "                self.saved_cnns[individual.encoding][\"epochs\"] = epochs\n",
    "\n",
    "        print(\"\\nEvery individual in the population has been evaluated! ...\")\n",
    "\n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def choose_winner(self, ind1, ind2) -> CNN:\n",
    "        \"\"\"\n",
    "        Choose a winner from the tournamen selection considering the accuracy\n",
    "        and the process time of two networks.\n",
    "\n",
    "        An individual would be better than other if it is 30% (or greater)\n",
    "        faster and it is maximum 3% less acurate.\n",
    "\n",
    "        Args:\n",
    "            ind1 (CNN): An individual\n",
    "            ind2 (CNN): An individual\n",
    "\n",
    "        Returns:\n",
    "            CNN: The winner individual\n",
    "        \"\"\"\n",
    "        # None of the selected individuals has been evaluated\n",
    "        if ind1.accuracy == 0.0 and ind2.accuracy == 0.0:\n",
    "            return random.choice([ind1, ind2])\n",
    "        \n",
    "        elif ind1.accuracy == 0.0 and ind2.accuracy != 0.0:\n",
    "            return ind2\n",
    "        \n",
    "        elif ind1.accuracy != 0.0 and ind2.accuracy == 0.0:\n",
    "            return ind1\n",
    "        \n",
    "        # Both of the individuals has been evaluated        \n",
    "        if abs(ind1.accuracy - ind2.accuracy) < 0.03:\n",
    "            fastest = ind1 if ind1.process_time < ind2.process_time else ind2\n",
    "            slowest = ind1 if ind1.process_time > ind2.process_time else ind2\n",
    "\n",
    "            if fastest.process_time / slowest.process_time <= 0.7:\n",
    "                return fastest\n",
    "            return slowest\n",
    "        \n",
    "        more_accurate = ind1 if ind1.accuracy > ind2.accuracy else ind2\n",
    "        \n",
    "        return more_accurate\n",
    "\n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def tournament_selection(self, num_individuals) -> list:\n",
    "        \"\"\"\n",
    "        A list containing the winners of the tournament selection\n",
    "\n",
    "        Args:\n",
    "            num_individuals (int): How many individuals to generate in the offspring\n",
    "\n",
    "        Returns:\n",
    "            list: The offspring of the population\n",
    "        \"\"\"\n",
    "\n",
    "#         print(\"Tournament Selection\".center(30, \"=\"))\n",
    "\n",
    "        offspring = []\n",
    "\n",
    "        # Fill the offspring by tournament\n",
    "        while len(offspring) < num_individuals:\n",
    "            # Select two individuals\n",
    "            ind1 = random.choice(self.population.individuals)\n",
    "            ind2 = random.choice(self.population.individuals)\n",
    "\n",
    "            winner = self.choose_winner(ind1, ind2)\n",
    "\n",
    "#             print(f\"Selected individuals: {ind1.encoding} acc: {round(ind1.accuracy, 4)} & {ind2.encoding} acc: {round(ind2.accuracy, 4)} Winner: {winner.encoding}\")\n",
    "\n",
    "            offspring.append(winner)\n",
    "\n",
    "        return offspring\n",
    "\n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def cross(self, parent1, parent2, cross_point) -> tuple:\n",
    "        \"\"\"\n",
    "        Returns the resulting individuals of crossing their parents\n",
    "\n",
    "        Args:\n",
    "            parent1 (CNN): One of the parents\n",
    "            parent2 (CNN): One of the parents\n",
    "            cross_point (int): Index of the genes list in wich the crossing will be done\n",
    "\n",
    "        Returns:\n",
    "            tuple: The decendents resulting from the crossing\n",
    "        \"\"\"\n",
    "        genes1 = parent1.genes[:cross_point+1] + parent2.genes[cross_point+1:]\n",
    "        genes2 = parent2.genes[:cross_point+1] + parent1.genes[cross_point+1:]\n",
    "\n",
    "        genes1 = \"-\".join(genes1)\n",
    "        genes2 = \"-\".join(genes2)\n",
    "\n",
    "        son1 = CNN(genes1, self.input_shape, self.output_shape)\n",
    "        son2 = CNN(genes2, self.input_shape, self.output_shape)\n",
    "\n",
    "        return son1, son2\n",
    "\n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def crossover(self) -> None:\n",
    "        \"\"\"\n",
    "        Performs the crossover in the population and replaces the needed individuals\n",
    "        \"\"\"\n",
    "#         print(\"Crossover\".center(20, \"=\"))\n",
    "        selected_indices = [] # Individuals selected for crossover\n",
    "        num_selected = 0\n",
    "\n",
    "        for index in range(self.population_size):\n",
    "            r = random.random()\n",
    "            # Se eligen los individuos de las posiciones i con a_i < prob_cruce\n",
    "            if r < self.crossover_rate:\n",
    "                selected_indices.append(index)\n",
    "                num_selected += 1\n",
    "        \n",
    "        # El número de seleccionados se hace par\n",
    "        if num_selected % 2 == 1:\n",
    "            num_selected -= 1\n",
    "\n",
    "#         print(f\"Num selected: {num_selected}\")\n",
    "#         print(f\"Selected indices: {selected_indices}\")\n",
    "#         print(f\"Individuals size: {len(self.population.individuals)}\")\n",
    "\n",
    "        for i in range(0, num_selected, 2):\n",
    "            parent1 = self.population.individuals[selected_indices[i]]\n",
    "            parent2 = self.population.individuals[selected_indices[i+1]]\n",
    "\n",
    "            # We choose a random crossover point from shortest parent\n",
    "            shortest_parent = parent1 if parent1.num_genes < parent2.num_genes else parent2\n",
    "            cross_point = random.randint(1, shortest_parent.num_genes-1)\n",
    "\n",
    "            # We create two individuals based on their parents\n",
    "            son1, son2 = self.cross(parent1, parent2, cross_point)\n",
    "            \n",
    "            # New individuals replace their parents\n",
    "#             print(f\"Parent {parent1.encoding} was replaced by {son1.encoding}\")\n",
    "#             print(f\"Parent {parent2.encoding} was replaced by {son2.encoding}\")\n",
    "\n",
    "            self.population.individuals[i]   = son1\n",
    "            self.population.individuals[i+1] = son2\n",
    "\n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def mutation(self) -> None:\n",
    "        \"\"\"\n",
    "        Performs the mutation in the population.\n",
    "        There are four types of mutations:\n",
    "            - Increment depth of the net\n",
    "            - Reduce depth of the net\n",
    "            - Change layer type\n",
    "            - Recreate a layer\n",
    "        \"\"\"\n",
    "\n",
    "        possible_mutations = (\"increment_depth\", \"reduce_depth\", \"change_layer_type\", \"recreate_layer\")\n",
    "\n",
    "        # We loop over the genes of every individual in population\n",
    "        for individual in self.population.individuals:\n",
    "\n",
    "            # We make a copy so we dont modify our list while iterating\n",
    "            mutated_genes = individual.genes.copy()\n",
    "\n",
    "            for n_gene, gene in enumerate(individual.genes):\n",
    "                r = random.random()\n",
    "                if r < self.mutation_rate:\n",
    "                    # Mutate\n",
    "#                     print(\"Mutation\".center(20, \"=\"))\n",
    "#                     print(f\"Individual to mutate: {individual.encoding}\")\n",
    "\n",
    "                    mutation_type = random.choice(possible_mutations)\n",
    "                    \n",
    "                    if mutation_type == \"increment_depth\":\n",
    "                        # Put a layer after this layer\n",
    "                        new_layer = Layer.random_layer()\n",
    "                        mutated_genes.insert(n_gene + 1, new_layer)\n",
    "                        break    \n",
    "\n",
    "                    elif mutation_type == \"reduce_depth\":\n",
    "                        # Delete the current layer\n",
    "                        removed = mutated_genes.pop(n_gene)\n",
    "#                         print(f\"{removed} Removed from layers\")\n",
    "                        break\n",
    "\n",
    "                    elif mutation_type == \"change_layer_type\":\n",
    "                        # Put Skip layer if Mean layer or vice versa\n",
    "                        if gene == \"mean\" or gene == \"max\":\n",
    "                            # Generate a skip layer\n",
    "                            mutated_genes[n_gene] = Layer.skip_layer_encode()\n",
    "                        else:\n",
    "                            mutated_genes[n_gene] = Layer.pooling_layer_encode()\n",
    "                        break\n",
    "                            \n",
    "                    elif mutation_type == \"recreate_layer\":\n",
    "                        if gene == \"mean\" or gene == \"max\":\n",
    "                            # Generate a skip layer\n",
    "                            mutated_genes[n_gene] = Layer.pooling_layer_encode()\n",
    "                        else:\n",
    "                            mutated_genes[n_gene] = Layer.skip_layer_encode()\n",
    "                        break\n",
    "\n",
    "#             print(f\"Individual before: {individual.genes}\")\n",
    "            individual.genes = mutated_genes\n",
    "#             print(f\"Individual after: {individual.genes}\")\n",
    "\n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def elitism(self) -> None:\n",
    "        \"\"\"\n",
    "        Performs elitism in the population\n",
    "        \"\"\"\n",
    "        best = self.population.best_individual\n",
    "        if best not in self.population.individuals:\n",
    "            self.population.individuals = sorted(self.population.individuals, key=lambda x: x.accuracy, reverse=False)\n",
    "            worst = self.population.individuals[0]\n",
    "#             print(f\"Replacing individual {worst.encoding} with accuracy {worst.accuracy} with best individual {best.encoding} with accuracy {best.accuracy}\")\n",
    "            self.population.individuals[0] = best\n",
    "\n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def delete_individual_copies(self) -> None:\n",
    "        \"\"\"\n",
    "        Delete the extra copies of individuals in the population\n",
    "        \"\"\"\n",
    "        individuals_set = set(self.population.individuals)\n",
    "        number_missing = len(self.population.individuals) - len(individuals_set)\n",
    "        new_individuals = [self.population.generate_individual(self.input_shape, self.output_shape) \\\n",
    "                           for _ in range(number_missing)]\n",
    "\n",
    "        new_population = [*individuals_set, *new_individuals]\n",
    "#         print(f\"Size of the new population: {len(new_population)}\")\n",
    "        \n",
    "        self.population.individuals = new_population\n",
    "        \n",
    "    # ====================================================================================\n",
    "    # ====================================================================================\n",
    "    def main_loop(self) -> None:\n",
    "        \"\"\"\n",
    "        The main loop of the Genetic Algorithm\n",
    "        \"\"\"\n",
    "        # Initialize populatiojn\n",
    "        self.population.initialize(self.input_shape, self.output_shape)\n",
    "\n",
    "        # Print individuals\n",
    "        print(\"Starting evolution loop with the next population:\")\n",
    "        self.population.print()\n",
    "\n",
    "        # Evaluate population\n",
    "        self.evaluate_population()\n",
    "\n",
    "        print(\"Individuals Summary\".center(30, \" \"))\n",
    "        self.population.print()\n",
    "        self.save_architectures()\n",
    "        \n",
    "        self.population.compute_mean_accuracy()\n",
    "        self.accuracy_history.append(self.population.mean_accuracy)\n",
    "        print(f\"Population mean accuracy: {self.population.mean_accuracy}\")\n",
    "\n",
    "        for generation in range(self.num_generations):\n",
    "            print(\"\".center(100, \"=\"))\n",
    "            print(f\"Generation {generation + 1}\")\n",
    "\n",
    "            # ========== Selection =============\n",
    "            self.population.individuals = self.tournament_selection(self.population_size)\n",
    "\n",
    "            # ========== Crossover =============\n",
    "            self.crossover()\n",
    "\n",
    "            # ========== Mutation ==============\n",
    "            self.mutation()\n",
    "            \n",
    "            best_individual = self.population.best_individual\n",
    "            print(f\"The best individual was {best_individual.encoding[:10]} with accuracy {round(best_individual.accuracy, 4)}\")\n",
    "\n",
    "            # = Delete duplicate individuals ==\n",
    "            self.delete_individual_copies()\n",
    "            \n",
    "            # ========== Evaluation ============\n",
    "            self.evaluate_population()\n",
    "            \n",
    "            # ======= Print population =========\n",
    "            print(\"Individuals Summary\".center(30, \" \"))\n",
    "            self.population.print()\n",
    "            \n",
    "            # ======= Mean accuracy of pop =========\n",
    "            self.population.compute_mean_accuracy()\n",
    "            self.accuracy_history.append(self.population.mean_accuracy)\n",
    "            print(f\"Population mean accuracy: {self.population.mean_accuracy}\")\n",
    "            \n",
    "            # =========== Elitism ==============\n",
    "            # Get worst individual only if is not already\n",
    "            self.elitism()\n",
    "            \n",
    "            # == Save architectures in file ====\n",
    "            self.save_architectures()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiUNUZd3qXhh"
   },
   "source": [
    "# Running our Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eff3OuvMqa9Q"
   },
   "source": [
    "## Preparing our parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnXXjdn-rGz4"
   },
   "source": [
    "### Lloading the architectures that have already been evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "8XCGmnMyrQ9-"
   },
   "outputs": [],
   "source": [
    "# Dictionary of saved architectures with it's parameters\n",
    "with open(\"evaluated_architectures.json\") as file:\n",
    "    saved_cnns = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XqVPrIcrRfy"
   },
   "source": [
    "### Lloading the data set with which the individuals will be evaluated\n",
    "\n",
    "### Out dataset: CIFAR 10\n",
    "It has 10 classes, wich are:\n",
    "\n",
    "| Label | Description |\n",
    "|-------|-------------|\n",
    "|   0   |   airplane  |\n",
    "|   1   |  automobile |\n",
    "|   2   |     bird    |\n",
    "|   3   |     cat     |\n",
    "|   4   |     deer    |\n",
    "|   5   |     dog     |\n",
    "|   6   |     frog    |\n",
    "|   7   |    horse    |\n",
    "|   8   |     ship    |\n",
    "|   9   |    truck    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ia_69QZsrdQI",
    "outputId": "790f2605-b9e9-4191-ebf9-2c0b0e1016f9"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3XqiDf2rd0i"
   },
   "source": [
    "### Setting the training parameters ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "0CQ18Hbi_NcN"
   },
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    \"epochs\" : 6,\n",
    "    \"batch_size\" : 16,\n",
    "    \"X_train\" : X_train,\n",
    "    \"X_test\" : X_test,\n",
    "    \"y_train_cat\" : y_train_cat,\n",
    "    \"y_test_cat\" : y_test_cat\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFFlUPBxqmiO"
   },
   "source": [
    "---\n",
    "## Evolution of our genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "jdDTFwbb-0n6"
   },
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(\n",
    "    population_size=10,  # How many CNN will be in the population\n",
    "    min_genes=10,        # Minimum depth of the CNN's\n",
    "    max_genes=25,        # Maximum depth of the CNN's\n",
    "    num_generations=10,\n",
    "    mutation_rate=0.05,  # Mutation rate (value by convention)\n",
    "    crossover_rate=0.4,  # Crossover rate (value by convention)\n",
    "    saved_cnns=saved_cnns, # Document that saves the individuals who have already been evaluated, thus saving resources\n",
    "    training_params=training_params # Parameters needed for training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "bd7XysHZDQKr",
    "outputId": "8f40c72b-7919-4245-8544-250e44d24da6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evolution loop with the next population:\n",
      " CNN Depth   Encoding (just first layers)                                             Accuracy    Process time\n",
      "-----------  ----------------------------------------------------------------------  ----------  --------------\n",
      "    15       mean_128_64_max_max_max_512_128_64_64_max_max_512_512                       0             0\n",
      "    15       mean_32_512_512_512_64_256_128_512_mean_64_256_128_128_32_32_max            0             0\n",
      "    16       64_256_64_64_256_256_128_64_max_64_32_mean_32_512_mean_512_64               0             0\n",
      "    10       max_128_256_32_256_512_512_256_64_64_256_512_128_512_32_64_512_512_64       0             0\n",
      "    11       256_256_mean_max_256_512_128_128_128_32_128_64_max_64_32_256_256            0             0\n",
      "    18       512_256_max_32_256_64_64_mean_512_32_32_256_mean_64_512_mean                0             0\n",
      "    20       128_64_mean_max_256_32_max_256_32_32_512_mean_32_64_mean                    0             0\n",
      "    17       64_256_64_64_max_128_128_mean_256_128_64_32_32_256_mean_128_512             0             0\n",
      "    10       32_512_512_512_128_128_mean_max_max_256_64_512_512_512_256_64_512           0             0\n",
      "    10       128_32_256_512_256_512_256_128_512_128_512_512_32_512_mean_128_256_max      0             0\n",
      "====================================================================================================\n",
      "Architecture: mean-128_64-max-max-max-512_128-64_64-max-max-512_512-256_32-128_512-max-mean-64_128, Depth: 15\n",
      "Training ...\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "ga.main_loop()\n",
    "t2 = time.perf_counter()\n",
    "print(f\"Time taken: {t2-t1} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing population mean accuracy during generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(1, 11, 1)\n",
    "y = ga.accuracy_history\n",
    "plt.plot(X, y, label=\"Mean accuracy\", marker=\"o\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"Population mean accuracy in each generation\")\n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"Mean accuracy\")\n",
    "plt.yticks(np.arange(0.65, 1, 0.05))\n",
    "plt.xticks(np.arange(1, 11, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoA6yPbO4UIH"
   },
   "source": [
    "# Getting the Best Individual of our last population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1CBmS3F4UIH"
   },
   "outputs": [],
   "source": [
    "best_individual = ga.population.best_individual\n",
    "print(best_individual.encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buWhdfrPct0L"
   },
   "source": [
    "# Comparison with famous Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our best individual from scratch with more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "batch_size = training_params[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate the model again to get fresh weights and train it from scratch\n",
    "genetic_model = best_individual.generate_model()\n",
    "\n",
    "# Compiling model\n",
    "genetic_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Model Checkpoint callback save the best model, not last.\n",
    "checkpoint_genetic_name = \"genetic_best.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_genetic_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_model_history = genetic_model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.15,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_result(genetic_model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_genetic = keras.models.load_model(\"genetic_best.h5\")\n",
    "genetic_validation = best_genetic.evaluate(X_test, y_test_cat, batch_size=batch_size)\n",
    "print(\" GENETIC Validation results \".center(50,\"=\"))\n",
    "print(f\"Test loss: {genetic_validation[0]}, Test accuracy: {genetic_validation[1]}\")\n",
    "\n",
    "time1 = time.perf_counter()\n",
    "predictions = best_genetic.predict(X_test)\n",
    "time2 = time.perf_counter()\n",
    "best_genetic_model_process_time = ((time2 - time1)/X_test.shape[0]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = tf.keras.applications.VGG19(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(32,32,3)\n",
    ")\n",
    "\n",
    "# Freezing layers\n",
    "for layer in vgg19_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Getting the last layer\n",
    "last_layer_name = vgg19_model.layers[-1].name\n",
    "last_layer = vgg19_model.get_layer(last_layer_name)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Adding fully connected layers to our pretrained model\n",
    "x = tf.keras.layers.GlobalMaxPooling2D()(last_output)\n",
    "x = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "vgg19_model = tf.keras.Model(vgg19_model.input, x)\n",
    "\n",
    "# Compiling the model\n",
    "vgg19_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Model Checkpoint callback save the best model, not last.\n",
    "checkpoint_vgg19_name = \"vgg19_best.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_vgg19_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg19_model_history = vgg19_model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.15,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_result(vgg19_model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vgg19 = tf.keras.models.load_model(\"vgg19_best.h5\")\n",
    "vgg19_validation = best_vgg19.evaluate(X_test, y_test_cat, batch_size=batch_size)\n",
    "print(\" VGG19 Validation results \".center(50,\"=\"))\n",
    "print(f\"Test loss: {vgg19_validation[0]}, Test accuracy: {vgg19_validation[1]}\")\n",
    "\n",
    "time1 = time.perf_counter()\n",
    "predictions = best_vgg19.predict(X_test)\n",
    "time2 = time.perf_counter()\n",
    "best_vgg19_model_process_time = ((time2 - time1)/X_test.shape[0]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ResNet50_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(32,32,3)\n",
    ")\n",
    "\n",
    "# Freezing layers\n",
    "for layer in ResNet50_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Getting the last layer\n",
    "last_layer_name = ResNet50_model.layers[-1].name\n",
    "last_layer = ResNet50_model.get_layer(last_layer_name)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Adding fully connected layers to our pretrained model\n",
    "x = tf.keras.layers.GlobalMaxPooling2D()(last_output)\n",
    "x = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "ResNet50_model = tf.keras.Model(ResNet50_model.input, x)\n",
    "\n",
    "# Compiling the model\n",
    "ResNet50_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Model Checkpoint callback save the best model, not last.\n",
    "checkpoint_ResNet50_name = \"ResNet50_model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_ResNet50_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_model_history = ResNet50_model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.15,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_result(ResNet50_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ResNet50 = tf.keras.models.load_model(checkpoint_ResNet50_name)\n",
    "ResNet50_validation = best_ResNet50.evaluate(X_test, y_test_cat, batch_size=batch_size)\n",
    "print(\" ResNet50 Validation results \".center(50, \"=\"))\n",
    "print(f\"Test loss: {ResNet50_validation[0]}, Test accuracy: {ResNet50_validation[1]}\")\n",
    "\n",
    "time1 = time.perf_counter()\n",
    "predictions = ResNet50_validation.predict(X_test)\n",
    "time2 = time.perf_counter()\n",
    "best_inceptionV3_model_process_time = ((time2 - time1)/X_test.shape[0]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list with the information of the trainings\n",
    "battle_info = [\n",
    "    [\"Best of GA\",  genetic_validation[1], best_genetic_model_process_time],\n",
    "    [\"VGG19\",       vgg19_validation[1], best_vgg19_model_process_time],\n",
    "    [\"ResNet50\", ResNet50_validation[1], best_inceptionV3_model_process_time]\n",
    "]\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        battle_info,\n",
    "        headers=[\"Network\", \"Accuracy\", \"Process time (ms)\"],\n",
    "        numalign=\"center\", stralign=\"center\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgYklEQVR4nO3dfbxVVb3v8c83FJ+fil0poJhhipqohFmeMh8K8giW2oEspauipZamHunWIS/31i31ZCclDXswuyqipYeMovIh0zQBBRUJ3eIDkOaWfNY09Hf/GGPpdLH23gvYc2/2nt/367Vee805xxzzN9fca/3mHGOtMRURmJlZdb2lpwMwM7Oe5URgZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4EFSNpgqRbOlj+a0lHd2dMZu2R9Lykd/V0HH2dE0EvIukmSU9J2qCsbUTE6Ij4ad5eh0ljdeTYj+2Kutqpfz9JN5VVv/WMiNg0Ipb0dBx9nRNBLyFpCPAvQABjOinbrzti6k6S1uvpGMrQF49VV+irx3td5UTQexwF3A5cAryp6UbSJZIulDRL0gvARyQNlvQLSW2SVki6oG6dc/PVxUOSRhfm3yTpWEk7AxcB++TL86fz8g3yuo9K+pukiyRtVFh/rKT5kp6V9KCkUZK+QUpiF+S6LpA0RFIU3/DFq4Z8NXKrpPMkrQDO6mzbhXqU13six3GPpF0bvaiSPidpkaTnJC2RdHzd8lX2J89/q6SfSPprfh2vLcR9S10dIendHRyrgyXdlbexVNJZdevvK+lPkp7OyydIel9+DfoVyn1S0oJ29nMjSf8p6RFJz0i6pfbaSRojaWGu/6Z87GvrPSzpDEl3S3pB0o8kvUOpCfE5Sb+XtFUuWzumE/Pr8pik0wt1jZR0W97OY/n/oH/d63SipAeABxq8dh+XdF/e7vK6uo+T1Crp75JmStqmrt4TJD2Qtz1Vkhq9TpUVEX70ggfQCnwB2Av4J/COwrJLgGeAD5KS+ybAAuC8/HxDYN9cdkJe/zigH/B54K+A8vKbgGMLZW+pi+M8YCbwVmAz4JfA/83LRuY4DspxDAR2qq83Tw8hXd2sV5hXv+2VwMnAesBGHW27LsaPAfOALQEBOwNbt/O6HgzskMt9GHgR2LOJ/fkVcCWwFbA+8OEOXrMA3t3OsdoQ2A/YLU+/F/gbcGguvx3wHDA+b+dtwPC87D5gdGE71wCntbOfU/PrOzAf9w8AGwA7Ai/kfVwf+HfS/1r/vN7DpBOQd+R1nwDuBPbIsd8AfL3umF5B+r/bDWgDDszL9wLen4/nEGARcErd6/S7fHw3avDaPQb8S36+VeE47Q88CeyZ9+l84Oa6eq/L/w/b5phG9fR7el169HgAfjRxkGBf0of3gDz9F+DUwvJLgEsL0/vkf/b1GtQ1AWgtTG+c3yjvzNM30U4iIH1YvgDsULeth/LzHwDntbMPr9ebp2sfGh0lgkeb3XbdtvYH7s8fOm9Zzdf6WuBLHe0PsDXwGrBVO69vZ4ng0k5i+G5tu8BXgGvaKXcmcFl+/lZSElsl4ZESzEvA7g2W/Qcwo67scmC/PP0wcGRh+c+BCwvTJwPX1h3TnQrLzwZ+1E78pxT3La+7fwev3aPA8cDmdWV+BJxdmN6U9H4ZUqhj38LyGcCk1fm/6OsPNw31DkcDv42IJ/P05dQ1DwFLC88HA49ExMp26nu89iQiXsxPN20ijhZS4piXL7GfBn6T59e2+2AT9TSruE+dbft1EXEDcAHpLPgJSdMkbd5oA5JGS7o9Nyk8DXwcGJAXt7c/g4G/R8RTa7Zbb9ovJO0t6UalZrxngBOaiAHg/wGHSNoE+BTwx4h4rEG5AaSz90b1bAM8UpuIiNdyfAMLZf5WeP5Sg+n6/53i/j2St4GkHSVdJ+lxSc8C3+SN/Wy0br3DSMfnEUl/kLRPO/vwPLCibh8eLzx/sUHMleZEsI7L7bifAj6c30CPA6cCu0vavVC0OIzsUmBbrX2HW/3QtE+S3vi7RMSW+bFFRNTeVEtJzSzN1PVC/rtxYd47O1ins22/ecWI70XEXsAwUvPHGfVllL599XPgXFJT25bALNLVR0f7sxR4q6QtGyx7obhPkur3qX6/ICX2mcDgiNiC1DfTWQxExHLgNuCTwGeBnzUqR3rt/tFOPX8lNT/V4hUp+Sxvp65mDC483zZvA+BC0tXs0IjYHPifvLGfNe0OhxwRcyJiLPB20pXbjLyofh82ITWhrc0+VIoTwbrvUOBV0gfa8PzYGfgjqQO5kTtI7anfkrSJpA0lfXANtv03YFCtQy+fLV4MnCfp7QCSBkr6WC7/I+Bzkg6Q9Ja8bKdCXa9/Hzwi2khv1M9I6ifpf9B+Emlm26/LHal7S1qf9MH8D1JTTr3+pDblNmClUqf5RwvLG+5PPuv+NfB9SVtJWl/Sh/I6C4BdJA2XtCFwVnv7VLAZ6QrjH5JGAp8uLLsMOFDSpyStJ+ltkoYXll9KatffDfhFo8rza/dj4DuStsmv9z45Ec4ADs77uD5wGvAy8Kcm4m7Pf0jaWNIuwOdIfSm1/XwWeD7/X3y+2Qol9Zd0pKQtIuKfuZ7aMb2CdJyG5336JvDniHh4LfahUpwI1n1HAz+JiEcj4vHag9T0cWSjs/6IeBU4BHg3qV11GfBva7DtG4CFwOOSas1SZ5I6E2/Pl/e/B96Tt3sH6Y1/HqlD9A+8cab2X8DhSt+w+V6edxzpTH0FsAudf/i0u+06m5OSxlOkJoMVwDn1hSLiOeCLpA/Dp0gfwDMLyzvan8+S2qH/QupAPSWvcz8wJcf2ANDM7zC+AEyR9BwwmTfOdImIR0nNIacBfwfmA8UrwWtyTNcUmvkaOR24B5iT6/k2qf9kMfAZUgfrk6T/m0Mi4pUm4m7PH0jH6Xrg3Ij4bSGGT5M6vy/mjQTRrM8CD+djfwJwJEBE/J7U1/Fz0gnQDsC4tYi/cmrfFDGzXkrSg8Dx+QOxJ+MYAjwErN9B/5Stg3xFYNaLSTqM1K5+Q0/HYr2Xf71n1kspDakxDPhs7gcwWyNuGjIzqzg3DZmZVVyvaxoaMGBADBkypKfDMDPrVebNm/dkRKzyA0zohYlgyJAhzJ07t6fDMDPrVSQ90t4yNw2ZmVWcE4GZWcU5EZiZVZwTgZlZxTkRmJlVnBOBmVnFORGYmVWcE4GZWcU5EZiZVVyv+2Wxma37Pnj+mtwQz1bXrSff2iX1+IrAzKzinAjMzCrOicDMrOKcCMzMKs6JwMys4kpNBJJGSVosqVXSpAbLt5V0o6S7JN0t6eNlxmNmZqsqLRFI6gdMBUaTbrA9XtKwumJfA2ZExB7AOOD7ZcVjZmaNlXlFMBJojYglEfEKMB0YW1cmgM3z8y2Av5YYj5mZNVDmD8oGAksL08uAvevKnAX8VtLJwCbAgSXGY2ZmDfR0Z/F44JKIGAR8HPiZpFVikjRR0lxJc9va2ro9SDOzvqzMRLAcGFyYHpTnFR0DzACIiNuADYEB9RVFxLSIGBERI1paWkoK18ysmspMBHOAoZK2l9Sf1Bk8s67Mo8ABAJJ2JiUCn/KbmXWj0hJBRKwETgJmA4tI3w5aKGmKpDG52GnAcZIWAFcAEyIiyorJzMxWVerooxExC5hVN29y4fl9gIcpNDPrQT3dWWxmZj3MicDMrOKcCMzMKs6JwMys4pwIzMwqzonAzKzinAjMzCrOicDMrOKcCMzMKs6JwMys4pwIzMwqzonAzKzinAjMzCrOicDMrOKcCMzMKs6JwMys4kpNBJJGSVosqVXSpAbLz5M0Pz/ul/R0mfGYmdmqSrtDmaR+wFTgIGAZMEfSzHxXMgAi4tRC+ZOBPcqKx8zMGivzimAk0BoRSyLiFWA6MLaD8uNJ9y02M7NuVGYiGAgsLUwvy/NWIWk7YHvghnaWT5Q0V9Lctra2Lg/UzKzK1pXO4nHA1RHxaqOFETEtIkZExIiWlpZuDs3MrG8rMxEsBwYXpgfleY2Mw81CZmY9osxEMAcYKml7Sf1JH/Yz6wtJ2gnYCritxFjMzKwdpSWCiFgJnATMBhYBMyJioaQpksYUio4DpkdElBWLmZm1r7SvjwJExCxgVt28yXXTZ5UZg5mZdWxd6Sw2M7Me4kRgZlZxpTYN9bS9zri0p0OohHnnHNXTIZjZWvAVgZlZxTkRmJlVnBOBmVnFORGYmVWcE4GZWcU5EZiZVZwTgZlZxTkRmJlVnBOBmVnFORGYmVWcE4GZWcU5EZiZVZwTgZlZxZWaCCSNkrRYUqukSe2U+ZSk+yQtlHR5mfGYmdmqShuGWlI/YCpwELAMmCNpZkTcVygzFPgK8MGIeErS28uKx8zMGivzimAk0BoRSyLiFWA6MLauzHHA1Ih4CiAinigxHjMza6DMRDAQWFqYXpbnFe0I7CjpVkm3SxrVqCJJEyXNlTS3ra2tpHDNzKqppzuL1wOGAvsB44GLJW1ZXygipkXEiIgY0dLS0r0Rmpn1cWUmguXA4ML0oDyvaBkwMyL+GREPAfeTEoOZmXWTMhPBHGCopO0l9QfGATPrylxLuhpA0gBSU9GSEmMyM7M6pSWCiFgJnATMBhYBMyJioaQpksbkYrOBFZLuA24EzoiIFWXFZGZmqyrt66MAETELmFU3b3LheQBfzg8zM+sBPd1ZbGZmPcyJwMys4pwIzMwqzonAzKzinAjMzCrOicDMrOKcCMzMKs6JwMys4pwIzMwqrtRfFputjUen7NbTIfR5206+p6dDsHWArwjMzCrOicDMrOKcCMzMKq7TRCDpEElOGGZmfVQzH/D/Bjwg6WxJO5UdkJmZda9OE0FEfAbYA3gQuETSbflm8pt1tq6kUZIWS2qVNKnB8gmS2iTNz49j12gvzMxsjTXV5BMRzwJXA9OBrYFPAHdKOrm9dST1A6YCo4FhwHhJwxoUvTIihufHD1d3B8zMbO0000cwRtI1wE3A+sDIiBgN7A6c1sGqI4HWiFgSEa+QksjYtQ/ZzMy6UjM/KDsMOC8ibi7OjIgXJR3TwXoDgaWF6WXA3o3ql/Qh4H7g1IhY2qCMmZmVpJmmobOAO2oTkjaSNAQgIq5fy+3/EhgSEe8Ffgf8tFGh3CcxV9Lctra2tdykmZkVNZMIrgJeK0y/mud1ZjkwuDA9KM97XUSsiIiX8+QPgb0aVRQR0yJiRESMaGlpaWLTZmbWrGYSwXq5jR+A/Lx/E+vNAYZK2l5Sf2AcMLNYQNLWhckxwKIm6jUzsy7UTCJokzSmNiFpLPBkZytFxErgJGA26QN+RkQslDSlUN8XJS2UtAD4IjBhdXfAzMzWTjOdxScAl0m6ABCpA/ioZiqPiFnArLp5kwvPvwJ8pelozcysy3WaCCLiQeD9kjbN08+XHpWZmXWbpu5HIOlgYBdgQ0kARMSUEuMyM7Nu0swPyi4ijTd0Mqlp6Ahgu5LjMjOzbtJMZ/EHIuIo4KmI+F/APsCO5YZlZmbdpZlE8I/890VJ2wD/JI03ZGZmfUAzfQS/lLQlcA5wJxDAxWUGZWZm3afDRJBvSHN9RDwN/FzSdcCGEfFMdwRnZmbl67BpKCJeIw0lXZt+2UnAzKxvaaaP4HpJh6n2vVEzM+tTmkkEx5MGmXtZ0rOSnpP0bMlxmZlZN2nml8Wd3pLSzMx6r04TQb5pzCrqb1RjZma9UzNfHz2j8HxD0i0o5wH7lxKRmZl1q2aahg4pTksaDHy3rIDMzKx7NdNZXG8ZsHNXB2JmZj2jmT6C80m/JoaUOIaTfmFsZmZ9QDNXBHNJfQLzgNuAMyPiM81ULmmUpMWSWiVN6qDcYZJC0oimojYzsy7TTGfx1cA/IuJVAEn9JG0cES92tJKkfqRfJR9Eak6aI2lmRNxXV24z4EvAn9dkB8zMbO009ctiYKPC9EbA75tYbyTQGhFL8g3vpwNjG5T738C3eWOUUzMz60bNJIINi7enzM83bmK9gaT7G9csy/NeJ2lPYHBE/KqjiiRNlDRX0ty2trYmNm1mZs1qJhG8kD+wAZC0F/DS2m44j2z6HeC0zspGxLSIGBERI1paWtZ202ZmVtBMH8EpwFWS/kq6VeU7Sbeu7MxyYHBhelCeV7MZsCtwUx7P7p3ATEljImJuE/WbmVkXaOYHZXMk7QS8J89aHBH/bKLuOcBQSduTEsA44NOFep8BBtSmJd0EnO4kYGbWvZq5ef2JwCYRcW9E3AtsKukLna0XESuBk4DZwCJgRkQslDRF0pi1DdzMzLpGM01Dx0VE8eY0T0k6Dvh+ZytGxCxgVt28ye2U3a+JWMzMrIs101ncr3hTmvz7gP7lhWRmZt2pmSuC3wBXSvpBnj4e+HV5IZmZWXdqJhGcCUwETsjTd5O+4WNmZn1Ap01D+Qb2fwYeJv1aeH9S56+ZmfUB7V4RSNoRGJ8fTwJXAkTER7onNDMz6w4dNQ39Bfgj8K8R0Qog6dRuicrMzLpNR01DnwQeA26UdLGkA0i/LDYzsz6k3UQQEddGxDhgJ+BG0lATb5d0oaSPdlN8ZmZWsmY6i1+IiMvzvYsHAXeRvklkZmZ9wGrdszginsojgR5QVkBmZta91uTm9WZm1oc4EZiZVZwTgZlZxTkRmJlVnBOBmVnFORGYmVVcqYlA0ihJiyW1SprUYPkJku6RNF/SLZKGlRmPmZmtqrREkG9gMxUYDQwDxjf4oL88InaLiOHA2cB3yorHzMwaK/OKYCTQGhFLIuIVYDowtlggIp4tTG4CRInxmJlZA83cmGZNDQSWFqaXAXvXF5J0IvBl0u0v929UkaSJpJvjsO2223Z5oGZmVdbjncURMTUidiCNX/S1dspMi4gRETGipaWlewM0M+vjykwEy4HBhelBeV57pgOHlhiPmZk1UGYimAMMlbS9pP7AOGBmsYCkoYXJg4EHSozHzMwaKK2PICJWSjoJmA30A34cEQslTQHmRsRM4CRJBwL/BJ4Cji4rHjMza6zMzmIiYhYwq27e5MLzL5W5fTMz61yPdxabmVnPciIwM6s4JwIzs4pzIjAzqzgnAjOzinMiMDOrOCcCM7OKcyIwM6s4JwIzs4pzIjAzqzgnAjOzinMiMDOrOCcCM7OKcyIwM6s4JwIzs4orNRFIGiVpsaRWSZMaLP+ypPsk3S3peknblRmPmZmtqrREIKkfMBUYDQwDxksaVlfsLmBERLwXuBo4u6x4zMyssTKvCEYCrRGxJCJeId2cfmyxQETcGBEv5snbSTe4NzOzblRmIhgILC1ML8vz2nMM8OtGCyRNlDRX0ty2trYuDNHMzNaJzmJJnwFGAOc0Wh4R0yJiRESMaGlp6d7gzMz6uDJvXr8cGFyYHpTnvYmkA4GvAh+OiJdLjMfMzBoo84pgDjBU0vaS+gPjgJnFApL2AH4AjImIJ0qMxczM2lFaIoiIlcBJwGxgETAjIhZKmiJpTC52DrApcJWk+ZJmtlOdmZmVpMymISJiFjCrbt7kwvMDy9y+mZl1bp3oLDYzs57jRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcaUmAkmjJC2W1CppUoPlH5J0p6SVkg4vMxYzM2ustEQgqR8wFRgNDAPGSxpWV+xRYAJweVlxmJlZx8q8VeVIoDUilgBImg6MBe6rFYiIh/Oy10qMw8zMOlBm09BAYGlhelmet9okTZQ0V9Lctra2LgnOzMySXtFZHBHTImJERIxoaWnp6XDMzPqUMhPBcmBwYXpQnmdmZuuQMhPBHGCopO0l9QfGATNL3J6Zma2B0hJBRKwETgJmA4uAGRGxUNIUSWMAJL1P0jLgCOAHkhaWFY+ZmTVW5reGiIhZwKy6eZMLz+eQmozMzKyH9IrOYjMzK48TgZlZxTkRmJlVnBOBmVnFORGYmVWcE4GZWcU5EZiZVZwTgZlZxTkRmJlVnBOBmVnFORGYmVWcE4GZWcU5EZiZVZwTgZlZxTkRmJlVnBOBmVnFlZoIJI2StFhSq6RJDZZvIOnKvPzPkoaUGY+Zma2qtEQgqR8wFRgNDAPGSxpWV+wY4KmIeDdwHvDtsuIxM7PGyrwiGAm0RsSSiHgFmA6MrSszFvhpfn41cIAklRiTmZnVKfOexQOBpYXpZcDe7ZWJiJWSngHeBjxZLCRpIjAxTz4vaXEpEa8bBlC3/+s6nXt0T4ewruh1x46v+7yroNcdP31xtY7fdu0tKPXm9V0lIqYB03o6ju4gaW5EjOjpOGz1+dj1blU+fmU2DS0HBhemB+V5DctIWg/YAlhRYkxmZlanzEQwBxgqaXtJ/YFxwMy6MjOBWrvC4cANERElxmRmZnVKaxrKbf4nAbOBfsCPI2KhpCnA3IiYCfwI+JmkVuDvpGRRdZVoAuujfOx6t8oeP/kE3Mys2vzLYjOzinMiMDOrOCeCLiLpRkkfq5t3iqQLJQ2VdJ2kByXNy2U/VCg3StIdkv4iaX4edmPbvOwISQslvSZpRGGd/pJ+IukeSQsk7ddd+9rbSXo1v873SvqlpC3XoI79JIWkQwrzruvsOEiaIGmbwvQlkh7K8cyXNDzPl6Tv5eFX7pa05+rGWBWS3iHpcklL8vvrNkmf6OJt1B+3HzYYKaHXciLoOlewamf3uDz/V8C0iNghIvYCTgbeBSBpV+B84OiI2CkihgOXAUNyHfcCnwRurqv7OICI2A04CPhPST6ezXkpIoZHxK6kLymcuIb1LAO+uprrTAC2qZt3Ro5neETMz/NGA0PzYyJw4RrG2KflkQiuBW6OiHfl99c40tfVu9IECsctIo6NiPu6eBs9xh8cXedq4OD8VVnyAHrbkN7It+VvSQEQEfdGxCV58kzgmxGxqLB8ZkTcnJ8viohGv6QeBtyQyzwBPA1U8scwa+k20i/ckbSDpN/ks8o/Stopzz8iXz0skFRMyAuAZyQdVF+ppL0k/SHXNVvS1pIOJx2jy/LZ/0YdxDUWuDSS24EtJW3dVTvdh+wPvBIRF9VmRMQjEXG+pH6SzpE0J19VHQ+vX83dJOnqfBV+WW1om2aPW15/RF5nlKQ78//H9T3wGqw1J4IuEhF/B+4gnclBOiuZAewC3NnBqp0tb88CYIyk9SRtD+zFm3/AZ51QGhjxAN74fcs04OR8Vnk68P08fzLwsYjYHRhTV803gK/V1bs+6Srv8FzXj4FvRMTVwFzgyHz2/1KtjvxBdZ6kDfK8RkO0DFy7Pe6TOnr/HAM8ExHvA94HHJffKwB7AKeQTqjeBXxwDY4bklqAi4HD8v/HEV29g92hVwwx0YvUmof+O/89BjiyWEDSNaSrhPsj4pN1y94GXA9sTGpKOreDbf0Y2Jn0D/oI8Cfg1a7ZjT5vI0nzSR+si4DfSdoU+ABwld4Y97D2oXwrcImkGcAvihVFxM2SkLRvYfZ7gF1zvZB+R/NYO7F8BXgc6E9KRGcCU9Zq7ypM0lRgX+AV0vvivfmMHtLIBUPzsjsiYlleZz6pKfZpmj9uNe8nNUs9BK+fEPY6TgRd67+B83LH3sYRMS93/r3eMRwRn8iXlLUP+YXAnsCCiFgBDJd0OrBpRxuKiJXAqbVpSX8C7u/KnenDXoqI4ZI2Jv3g8UTgEuDp3EfzJhFxgqS9gYOBeZL2qitSuypYmacFLIyIfToLJCJqHzQvS/oJ6UoEmhuixdL757DaREScKGkA6QTpUdIV3uziCrlD/+XCrFdJn4VNH7e+xk1DXSgingduJJ2tX5FnX0667Cw2KWxceH428FVJO7ezvCFJG0vaJD8/CFjZlzqvukNEvAh8ETgNeBF4SNIR8Pq3dnbPz3eIiD9HxGSgjbomuIj4LbAV8N48azHQImmfvP76knbJy54DNqutW2v3z23Uh5K+HACpueqoHMf7SU0cnZ2dVtENwIaSPl+YV3v/zAY+n5t8kLRj7T3TjqaPW8HtwIdqTU6S3rrmu9JzfEXQ9a4AriF/gygiXpL0r8B3JH0X+Bvpn+r/5OX3SPoScKmkzUnD4D4KfB1A6Wtw5wMtwK8kzY+IjwFvB2ZLeo10pvjZ7tvFviMi7pJ0NzCe1Ix3oaSvAeuT7qGxADhH0lDSGeP1ed6H66r6BumKkIh4JTdHfE/SFqT32XdJZ6+XABdJegnYh9QB2ZLrng+ckOubBXwcaCUlqc919b73BRERkg4lXYn/OylRv0BqYruK1ORzZ060baRk215dq3Pcauu0KQ2T/wulb+09QfoWX6/iISbMzCrOTUNmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgfZakQ5VGCN1pNdd7OP8oqX7+GEmTCnWv0eiTkraU9IU1WdesDE4E1peNB27Jf99E0mr/hiYPBvitPHkoaZyaNbElsNqJII+NZNblnAisT8pjB+1LGu9pXJ63n9KoojOB+5RGpzxXaWTRuyWdXKji5Dyi5D16YxTSCZIukPQB0uBz5+TRKHdQ+yOXvkPSNUojUy7I634L2CGve06O67pC7BdImpCfPyzp25LuBI6Q9FGl8fbvlHRV3k+zteJfFltfNRb4TUTcL2lFYXygPYFdI+KhPCzBEGB4RKysGx7gyYjYMzfhnA4cW1sQEX/KyeS6PDIlSsMPnxARD+Rxib5PGiL5e8Af8hhT/UhjSE3KMQzP6+7Xyb6syLEMIA16d2BEvCDpTODLeJA6W0tOBNZXjQf+Kz+fnqevI406+VCefyBwUR7Ar37kyNooo/NINwZqlzoeuXR/4Khc/6uk+xdstZr7cmX++35Sc9SteTv9SfdTMFsrTgTW5+Qz+/2B3SQFaTjhIN0p7oUmq6mNTlkbmbIjb6GdkUubtJI3N9NuWLe8FrOA30XEKn0eZmvDfQTWFx0O/CwitouIIRExGHgI+Je6cr8Djq91HK/myJGvj0YZEc/SzsilpEHqPp/n98uDmdWPZPkIMEzSBkr3Tz6gnW3eThrJ9t25vk0k7bgaMZs15ERgfdF40giwRT9n1W8P/ZA00uvdkhYAn16NbUwHzpB0l6QdSCOXHpPrWUjqowD4EvARSfeQmpmG5ftO3Jo7qc+JiKWku9ndm//e1WiDEdFGunfuFXnE1NuA1fpqrFkjHn3UzKzifEVgZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZx/x9UnkrdHQVTFAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_list = [genetic_validation[1], vgg19_validation[1], ResNet50_validation[1]]\n",
    "\n",
    "sns.barplot(x=[\"Best Individual\", \"VGG19\", \"ResNet50\"], y=accuracy_list)\n",
    "plt.title(\"Architecture accuracy comparison\")\n",
    "plt.xlabel(\"Architecture\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AutoCNN.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "04f21b54aa8a0702a20e87f78ee0e21137e9070717c4091640b06aa5476c51f5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
